---
layout: post
title: "数据预处理方式（去均值，归一化，PCA降维）"
date: "2023-08-24"
categories: 
  - "数学"
---

# 去均值

各个维度都减去对应维度的均值，使得各个维度都中心化为0.

原因是容易拟合，如果某个特征值比较大，会造成w\*x+b的结果也比较大，这样激活函数relu输出时，会导致对应数值的变化量过小，进行反向传播时因为这里要进行梯度运算，会造成梯度消散问题，导致参数改变量过小，也就不容易拟合。

 

#  归一化

- 最值归一化，比如最大值为1，最小值为-1，适用于本来就分布在有限范围内的数据。
- 均值方差归一化，一般是把均值归一化为0，方差归一化为1，适用于分布没有明显边界的情况。

归一化效果比较，

[![]](http://127.0.0.1/?attachment_id=5195)[![]](http://127.0.0.1/?attachment_id=5194)

# PCA

pca是指通过抛弃信息量较少的维度，保留主要的特征信息对数据进行降维处理，思路上是使用少数几个有代表性，互不相关的特征来代替原先大量的，存在一定关联性的特征，从而加速机器学习过程。

# 白化

去掉数据之间的相关关联和令方差均一化，由于图像中相邻像素之间具有很强的相关性，所以用于训练时很多输入是冗余的，
