---
layout: post
title: "opencv简单总结"
date: "2021-06-05"
categories: 
  - "python"
  - "图像处理"
---

# gui特性

## 图片

- - cv2.imread  ： 读取图片
        - 第二个参数
            - cv2.IMREAD\_COLOR：读入一副彩色图像。图像的透明度会被忽略，这是默认参数。
            -  cv2.IMREAD\_GRAYSCALE：以灰度模式读入图像
            - cv2.IMREAD\_UNCHANGED：读入一幅图像，并且包括图像的 alpha 通道
        - 警告：就算图像的路径是错的，OpenCV 也不会提醒你的，但是当你使用命令print img时得到的结果是None。
    - cv2.imshow ： 显示图片
    - cv2.imwrite ： 保存图片
    - 例子
        
        ```
        import numpy as np
        import cv2
        
        img = cv2.imread('messi5.jpg',0)
        cv2.imshow('image',img)
        k = cv2.waitKey(0) # 　警告：如果你用的是 64 位系统，你需要将  k = cv2.waitKey(0) 这行改成k = cv2.waitKey(0)&0xFF。
        if k == 27:         # wait for ESC key to exit
            cv2.destroyAllWindows()
        elif k == ord('s'): # wait for 's' key to save and exit
            cv2.imwrite('messigray.png',img)
            cv2.destroyAllWindows()
        ```
        
         
        
         

### 中文读取和保存

```
## 读取图像，解决imread不能读取中文路径的问题
def cv_imread(filePath):
    cv_img=cv2.imdecode(np.fromfile(filePath,dtype=np.uint8),-1)
    ## imdecode读取的是rgb，如果后续需要opencv处理的话，需要转换成bgr，转换后图片颜色会变化
    cv_img=cv2.cvtColor(cv_img,cv2.COLOR_RGB2BGR)
    return cv_img

def saveImg(img, filepath):
    # 保存图片
    cv2.imencode(".jpg", img)[1].tofile(filepath)
```

 

## 视频

- - - cv2.VideoCapture(0) ： 参数可以是设备的索引号，或者是一个视频文件
        - ret, frame = cap.read()
            - ret ： True表示读取的是正确的
            - frame ： 表示读取的图像
    - 例子
        
        ```
        import numpy as np
        import cv2
        
        cap = cv2.VideoCapture(0)
        
        while(True):
            # Capture frame-by-frame
            ret, frame = cap.read()
        
            # Our operations on the frame come here
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
            # Display the resulting frame
            cv2.imshow('frame',gray)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        # When everything done, release the capture
        cap.release()
        cv2.destroyAllWindows()
        ```
        
         

## 绘图函数

- cv2.line ： 画线
- cv2.rectangle ： 画矩形
- cv2.circle ： 画圆形
- cv2.ellipse ： 画椭圆
- cv2.polylines ： 画多边形
- cv2.putText : 文字

## 鼠标处理事件cv2.setMouseCallback

```
import cv2
import numpy as np

drawing = False # true if mouse is pressed
mode = True # if True, draw rectangle. Press 'm' to toggle to curve
ix,iy = -1,-1

# mouse callback function
def draw_circle(event,x,y,flags,param):
    global ix,iy,drawing,mode

    if event == cv2.EVENT_LBUTTONDOWN:
        drawing = True
        ix,iy = x,y

    elif event == cv2.EVENT_MOUSEMOVE:
        if drawing == True:
            if mode == True:
                cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)
            else:
                cv2.circle(img,(x,y),5,(0,0,255),-1)

    elif event == cv2.EVENT_LBUTTONUP:
        drawing = False
        if mode == True:
            cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)
        else:
            cv2.circle(img,(x,y),5,(0,0,255),-1)
# Next we have to bind this mouse callback function to OpenCV # # window. In the main loop, we should set a keyboard binding for # key ‘m’ to toggle between rectangle and circle.
img = np.zeros((512,512,3), np.uint8)
cv2.namedWindow('image')
cv2.setMouseCallback('image',draw_circle)

while(1):
    cv2.imshow('image',img)
    k = cv2.waitKey(1) & 0xFF
    if k == ord('m'): # 切换模式
        mode = not mode
    elif k == 27:
        break

cv2.destroyAllWindows()
```

## 用滑动条做调色板

### cv2.createTrackbar()

参数

- 第一个参数是滑动条的名字
- 第二个参数是滑动条被放置窗口的名字
- 第三个参数是滑动条的默认位置。
- 第四个参数是滑动条的最大值
- 第五个函数是回调函数，每次滑动条的滑动都会调用回调函数。回调函数通常都会含有一个默认参数，就是滑动条的位置。

## 例子

```
import cv2
import numpy as np
def nothing(x):
    pass
# 当鼠标按下时变为 True
drawing=False
# 如果 mode 为 true 绘制矩形。按下 'm' 变成绘制曲线。
mode=True
ix,iy=-1,-1
# 创建回调函数
def draw_circle(event,x,y,flags,param):
    r=cv2.getTrackbarPos('R','image')
    g=cv2.getTrackbarPos('G','image')
    b=cv2.getTrackbarPos('B','image')
    color=(b,g,r)
    global ix,iy,drawing,mode
    # 当按下左键是返回起始位置坐标
    if event==cv2.EVENT_LBUTTONDOWN:
        drawing=True
        ix,iy=x,y
    # 当鼠标左键按下并移动是绘制图形。 event 可以查看移动， flag 查看是否按下
    elif event==cv2.EVENT_MOUSEMOVE and flags==cv2.EVENT_FLAG_LBUTTON:
        if drawing==True:
            if mode==True:
                cv2.rectangle(img,(ix,iy),(x,y),color,-1)
            else:
                # 绘制圆圈，小圆点连在一起就成了线， 3 代表了笔画的粗细
                cv2.circle(img,(x,y),3,color,-1)
                # 下面注释掉的代码是起始点为圆心，起点到终点为半径的
                # r=int(np.sqrt((x-ix)**2+(y-iy)**2))
                # cv2.circle(img,(x,y),r,(0,0,255),-1)
                # 当鼠标松开停止绘画。
    elif event==cv2.EVENT_LBUTTONUP:
        drawing==False
        # if mode==True:
            # cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)
        # else:
            # cv2.circle(img,(x,y),5,(0,0,255),-1)
img=np.zeros((512,512,3),np.uint8)
cv2.namedWindow('image')
cv2.createTrackbar('R','image',0,255,nothing)
cv2.createTrackbar('G','image',0,255,nothing)
cv2.createTrackbar('B','image',0,255,nothing)
cv2.setMouseCallback('image',draw_circle)
while(1):
    cv2.imshow('image',img)
    
    k=cv2.waitKey(1)&0xFF
    if k==ord('m'):
        mode=not mode
    elif k==27:
        break
```

# 图像基本操作

## 获取并修改像素值

方法：

- ```
    import cv2
    import numpy as np
    img=cv2.imread('messi5.jpg')
    px=img[100,100]
    print(px)
    blue=img[100,100,0]
    print(blue)
    ```
    
     
- ```
    import cv2
    import numpy as np
    img=cv2.imread('messi5.jpg')
    print(img.item(10,10,2))
    img.itemset((10,10,2),100)
    print(img.item(10,10,2))
    # 59
    # 100
    ```
    
     

## 获取图像属性shape

```
import cv2
import numpy as np
img=cv2.imread('messi5.jpg')
print(img.shape)

##(342, 548, 3)
```

 

## 图像 ROI

```
import cv2
import numpy as np
img=cv2.imread('messi5.jpg')
ball=img[280:340,330:390]
img[273:333,100:160]=ball
img=cv2.imshow('test', img)
cv2.waitKey(0)
```

## 拆分及合并图像通道

```
import cv2
import numpy as np
img=cv2.imread('/home/duan/workspace/opencv/images/roi.jpg')
b,g,r=cv2.split(img)
img=cv2.merge(b,g,r)
```

```
import cv2
import numpy as np
img=cv2.imread('/home/duan/workspace/opencv/images/roi.jpg')
img[:,:,2]=0
```

## 为图像扩边（填充）

如果你想在图像周围创建一个边，就像相框一样，你可以使用 cv2.copyMakeBorder()函数。这经常在卷积运算或 0 填充时被用到。这个函数包括如下参数： • src 输入图像 • top, bottom, left, right 对应边界的像素数目。 • borderType 要添加那种类型的边界，类型如下： – cv2.BORDER\_CONSTANT 添加有颜色的常数值边界，还需要下一个参数（value）。 – cv2.BORDER\_REFLECT 边界元素的镜像。比如: fedcba|abcde-fgh|hgfedcb – cv2.BORDER\_REFLECT\_101 or cv2.BORDER\_DEFAULT跟上面一样，但稍作改动。例如: gfedcb|abcdefgh|gfedcba – cv2.BORDER\_REPLICATE 重复最后一个元素。例如: aaaaaa|abcdefgh|hhhhhhh – cv2.BORDER\_WRAP 不知道怎么说了, 就像这样: cdefgh|abcdefgh|abcdefg • value 边界颜色，如果边界的类型是 cv2.BORDER\_CONSTANT

 

```
import cv2
import numpy as np
from matplotlib import pyplot as plt
BLUE=[255,0,0]
img1=cv2.imread('opencv_logo.png')
replicate = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REPLICATE)
reflect = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT)
reflect101 = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT_101)
wrap = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_WRAP)
constant= cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE)
plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')
plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')
plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')
plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')
plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')
plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')
plt.show()
```

[![](/assets/image/default/1230045-20180207203721529-1496452891.png)](http://127.0.0.1/?attachment_id=3865)

# 图像上的算术运算

## 图像加法

```
x = np.uint8([250])
y = np.uint8([10])
print cv2.add(x,y) # 250+10 = 260 => 255
[[255]]
print x+y # 250+10 = 260 % 256 = 4
[4]
```

注意：OpenCV 中的加法与 Numpy 的加法是有所不同的。OpenCV 的加法是一种饱和操作，而 Numpy 的加法是一种模操作。

## 图像混合

$latex g(x) = (1-\\alpha)f\_0(x) + \\alpha f\_1(x)$

cv2.addWeighted()  ： $latex dst = \\alpha \\cdot img1 + \\beta \\cdot img2 + \\gamma$

 

## 按位操作

AND，OR，NOT，XOR

```
import cv2
import numpy as np
# Load two images
img1 = cv2.imread('messi5.jpg')
img2 = cv2.imread('opencv-logo-white.png')

# I want to put logo on top-left corner, So I create a ROI
rows,cols,channels = img2.shape
roi = img1[0:rows, 0:cols ]

# Now create a mask of logo and create its inverse mask also
img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)
ret, mask = cv2.threshold(img2gray, 10, 255, cv2.THRESH_BINARY)
mask_inv = cv2.bitwise_not(mask)

# Now black-out the area of logo in ROI
img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)

# Take only region of logo from logo image.
img2_fg = cv2.bitwise_and(img2,img2,mask = mask)

# Put logo in ROI and modify the main image
dst = cv2.add(img1_bg,img2_fg)
img1[0:rows, 0:cols ] = dst

cv2.imshow('res',img1)
cv2.waitKey(0)
cv2.destroyAllWindows(
```

# 颜色空间转换

## 颜色空间

### RGB

### HSV

- H - 色度 （由光线波长决定） , 也就是跟红色的角度
- S - 饱和度 （纯色/颜色灰度），切面上，到中心点的距离跟半径的比值
- V - 亮度值（光强）， 到圆锥顶点距离的比值。

[![](/assets/image/default/900592-20160727130231466-1525470417.png)](http://127.0.0.1/?attachment_id=4588)[![](/assets/image/default/900592-20160727130251013-1162701264.png)](http://127.0.0.1/?attachment_id=4589)

1、RGB转化到HSV的算法： max=max(R,G,B) min=min(R,G,B) V=max(R,G,B) S=(max-min)/max ifR = max,H =(G-B)/(max-min)\* 60 ifG = max,H = 120+(B-R)/(max-min)\* 60 ifB = max,H = 240 +(R-G)/(max-min)\* 60 ifH < 0,H = H+ 360

2、HSV转化到RGB的算法： if s = 0 R=G=B=V else H /= 60; i = INTEGER(H) f = H - i a = V \* ( 1 - s ) b = V \* ( 1 - s \* f ) c = V \* ( 1 - s \* (1 - f ) ) switch(i) case 0: R = V; G = c; B = a; case 1: R = b; G = v; B = a; case 2: R = a; G = v; B = c; case 3: R = a; G = b; B = v; case 4: R = c; G = a; B = v; case 5: R = v; G = a; B = b;

 

### Lab

颜色之间的欧式距离有具体含义–距离越大，人眼感官两种颜色差距越远

- L 通道：像素亮度，上白下黑 中间灰
- a 通道：左绿 右红
- b 通道：一端纯蓝，一端纯黄

 

[![](/assets/image/default/v2-90046d409dd6ab2fd0867cb79af29ac4_720w.jpg)](http://127.0.0.1/?attachment_id=4591)

 

### LCH颜色空间

L是亮度值，C是表示色饱和度，h表示色调角

[![](/assets/image/default/ABUIABAEGAAg8Knd5wUomO3EoAMwwwE4qwE.png)](http://127.0.0.1/?attachment_id=4593)

 

 

## 转换颜色空间 cv2.cvtColor(input\_image ，flag)

经常用到的也就两种：BGR↔Gray 和 BGR↔HSV。

 

## 物体追踪

```
import cv2
import numpy as np

cap = cv2.VideoCapture(r'你的视频文件')

while(1):

    # Take each frame
    _, frame = cap.read()

    # Convert BGR to HSV
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

    # define range of blue color in HSV
    lower_blue = np.array([110,50,50])
    upper_blue = np.array([130,255,255])

    # Threshold the HSV image to get only blue colors
    mask = cv2.inRange(hsv, lower_blue, upper_blue)

    # Bitwise-AND mask and original image
    res = cv2.bitwise_and(frame,frame, mask= mask)

    cv2.imshow('frame',frame)
    cv2.imshow('mask',mask)
    cv2.imshow('res',res)
    k = cv2.waitKey(5) & 0xFF
    if k == 27:
        break

cv2.destroyAllWindows()
```

# 几何变换

- cv2.warpAffine ：  2 × 3 的变换矩阵
- cv2.warpPerspective ： 3 × 3 的变换矩阵

## 平移

$latex 　M = \\begin{bmatrix} 1 & 0 & t\_x \\\\ 0 & 1 & t\_y \\end{bmatrix}$

你可以使用 Numpy 数组构建这个矩阵（数据类型是 np.float32），然后把它传给函数 cv2.warpAffine()。看看下面这个例子吧，它被移动了（100,50）个像素。

```
import cv2
import numpy as np

img = cv2.imread('messi5.jpg',0)
rows,cols = img.shape

M = np.float32([[1,0,100],[0,1,50]])
dst = cv2.warpAffine(img,M,(cols,rows))

cv2.imshow('img',dst)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

## 旋转

一般图像旋转矩阵如下，

$latex M = \\begin{bmatrix} cos\\theta & -sin\\theta \\\\ sin\\theta & cos\\theta \\end{bmatrix}$

opencv允许在任何位置旋转：

$latex \\begin{bmatrix} \\alpha & \\beta & (1- \\alpha ) \\cdot center.x - \\beta \\cdot center.y \\\\ - \\beta & \\alpha & \\beta \\cdot center.x + (1- \\alpha ) \\cdot center.y \\end{bmatrix}$

为了构建这个旋转矩阵，OpenCV 提供了一个函数：cv2.getRotationMatrix2D。

```
import cv2
import numpy as np
img=cv2.imread('messi5.jpg',0)
rows,cols=img.shape
# 这里的第一个参数为旋转中心，第二个为旋转角度，第三个为旋转后的缩放因子
# 可以通过设置旋转中心，缩放因子，以及窗口大小来防止旋转后超出边界的问题
M=cv2.getRotationMatrix2D((cols/2,rows/2),45,0.6)
# 第三个参数是输出图像的尺寸中心
dst=cv2.warpAffine(img,M,(2*cols,2*rows))
while(1):
    cv2.imshow('img',dst)
    if cv2.waitKey(1)&0xFF==27:
        break
cv2.destroyAllWindows()
```

## 仿射变换

在仿射变换中，原图中所有的平行线在结果图像中同样平行。为了创建这个矩阵我们需要从原图像中找到三个点以及他们在输出图像中的位置。然后cv2.getAffineTransform 会创建一个 2x3 的矩阵，最后这个矩阵会被传给函数 cv2.warpAffine。

```
img = cv2.imread('drawing.png')
rows,cols,ch = img.shape

pts1 = np.float32([[50,50],[200,50],[50,200]])
pts2 = np.float32([[10,100],[200,50],[100,250]])

M = cv2.getAffineTransform(pts1,pts2)

dst = cv2.warpAffine(img,M,(cols,rows))

plt.subplot(121),plt.imshow(img),plt.title('Input')
plt.subplot(122),plt.imshow(dst),plt.title('Output')
plt.show()
```

## 透视变换

对于视角变换，我们需要一个 3x3 变换矩阵。在变换前后直线还是直线。要构建这个变换矩阵，你需要在输入图像上找 4 个点，以及他们在输出图像上对应的位置。这四个点中的任意三个都不能共线。这个变换矩阵可以有函数 cv2.getPerspectiveTransform() 构建。然后把这个矩阵传给函数cv2.warpPerspective。

```
img = cv2.imread('sudokusmall.png')
rows,cols,ch = img.shape

pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])

M = cv2.getPerspectiveTransform(pts1,pts2)

dst = cv2.warpPerspective(img,M,(300,300))

plt.subplot(121),plt.imshow(img),plt.title('Input')
plt.subplot(122),plt.imshow(dst),plt.title('Output')
plt.show()
```

 

# 图像阈值

## 简单阈值cv2.threshhold

**cv2.threshold(src, thresh, maxval, type\[, dst\]) → retval, dst**

- src：表示的是图片源
- thresh：表示的是阈值（起始值）
- maxval：表示的是最大值
- type：表示的是这里划分的时候使用的是什么类型的算法\*

 

像素值高于阈值时，我们给这个像素赋予一个新值（可能是白色），否则我们给它赋予另外一种颜色（也许是黑色）。

阈值类型type：

-  cv2.THRESH\_BINARY
- cv2.THRESH\_BINARY\_INV
- cv2.THRESH\_TRUNC
-  cv2.THRESH\_TOZERO
- cv2.THRESH\_TOZERO\_INV
- cv2.THRESH\_OTSU : 一种自适应阈值的。

[![](/assets/image/default/1230045-20180221205026282-2028541473.png)](http://127.0.0.1/?attachment_id=3867)

## 自适应阈值cv2.adaptiveThreshold

这种方法需要我们指定三个参数，返回值只有一个。 • Adaptive Method- 指定计算阈值的方法。 – cv2.ADPTIVE\_THRESH\_MEAN\_C：阈值取自相邻区域的平均值 – cv2.ADPTIVE\_THRESH\_GAUSSIAN\_C：阈值取值相邻区域的加权和，权重为一个高斯窗口。 • Block Size - 邻域大小（用来计算阈值的区域大小）。 • C - 这就是是一个常数，阈值就等于的平均值或者加权平均值减去这个常数。

 

```
import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread('dave.jpg',0)
img = cv2.medianBlur(img,5)

ret,th1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)
th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\
            cv2.THRESH_BINARY,11,2)
th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY,11,2)

titles = ['Original Image', 'Global Thresholding (v = 127)',
            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']
images = [img, th1, th2, th3]

for i in xrange(4):
    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')
    plt.title(titles[i])
    plt.xticks([]),plt.yticks([])
plt.show()
```

## Otsu’ ’s 二值化

双峰图，Otsu 算法就是要找到一个阈值（t）, 使得同一类加权方差最小，需要满足下列关系式：

$$ \\sigma\_w^2(t) = q\_1(t)\\sigma\_1^2(t)+q\_2(t)\\sigma\_2^2(t) $$

其中

$$ q\_1(t) = \\sum\_{i=1}^{t} P(i) \\quad \\& \\quad q\_1(t) = \\sum\_{i=t+1}^{I} P(i) \\mu\_1(t) = \\sum\_{i=1}^{t} \\frac{iP(i)}{q\_1(t)} \\quad \\& \\quad \\mu\_2(t) = \\sum\_{i=t+1}^{I} \\frac{iP(i)}{q\_2(t)} \\sigma\_1^2(t) = \\sum\_{i=1}^{t} \[i-\\mu\_1(t)\]^2 \\frac{P(i)}{q\_1(t)} \\quad \\& \\quad \\sigma\_2^2(t) = \\sum\_{i=t+1}^{I} \[i-\\mu\_1(t)\]^2 \\frac{P(i)}{q\_2(t)} $$

其实就是在两个峰之间找到一个阈值 t，将这两个峰分开，并且使每一个峰内的方差最小,实现这个算法的 Python 代码如下：

```
img = cv2.imread('noisy2.png',0)
blur = cv2.GaussianBlur(img,(5,5),0)

# find normalized_histogram, and its cumulative distribution function
hist = cv2.calcHist([blur],[0],None,[256],[0,256])
hist_norm = hist.ravel()/hist.max()
Q = hist_norm.cumsum()

bins = np.arange(256)

fn_min = np.inf
thresh = -1

for i in xrange(1,256):
    p1,p2 = np.hsplit(hist_norm,[i]) # probabilities
    q1,q2 = Q[i],Q[255]-Q[i] # cum sum of classes
    b1,b2 = np.hsplit(bins,[i]) # weights

    # finding means and variances
    m1,m2 = np.sum(p1*b1)/q1, np.sum(p2*b2)/q2
    v1,v2 = np.sum(((b1-m1)**2)*p1)/q1,np.sum(((b2-m2)**2)*p2)/q2

    # calculates the minimization function
    fn = v1*q1 + v2*q2
    if fn < fn_min:
        fn_min = fn
        thresh = i

# find otsu's threshold value with OpenCV function
ret, otsu = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)
prin(thresh,ret)
```

 

# 图像平滑

## 2D卷积

cv.filter2D(src, ddepth, kernel\[, dst\[, anchor\[, delta\[, borderType\]\]\]\])

- src ： 原图像
- ddepth ： 目标图像所需深度，当ddepth=-1时，表示输出图像与原图像有相同的深度。
- kernel ： 卷积核
- anchor ： 内核的锚点，指示内核中过滤点的相对位置;锚应位于内核中;默认值（-1，-1）表示锚位于内核中心。
- detal ： 在将它们存储在dst中之前，将可选值添加到已过滤的像素中。类似于偏置。
- borderType ： 像素外推法，参见BorderTypes

 

 

- LPF ： 低通滤波，去除噪声
- HPF ： 高通滤波，找到图像边缘。

### 平均

这是由一个归一化卷积框完成的。他只是用卷积框覆盖区域所有像素的平均值来代替中心元素。可以使用函数 cv2.blur() 和 cv2.boxFilter() 来完这个任务

### 高斯模糊

现在把卷积核换成高斯核（简单来说，方框不变，将原来每个方框的值是相等的，现在里面的值是符合高斯分布的，方框中心的值最大，其余方框根据距离中心元素的距离递减，构成一个高斯小山包。cv2.GaussianBlur()

### 中值模糊

卷积框对应像素的中值来替代中心像素的值。这个滤波器经常用来去除椒盐噪声。前面的滤波器都是用计算得到的一个新值来取代中心像素的值，而中值滤波是用中心像素周围（也可以使他本身）的值来取代他。他能有效的去除噪声。卷积核的大小也应该是一个奇数。cv2.medianBlur

### 双边滤波

函数 cv2.bilateralFilter() 能在保持边界清晰的情况下有效的去除噪音。但是这种操作与其他滤波器相比会比较慢。我们已经知道高斯滤波器是求中心点邻近区域像素的高斯加权平均值。这种高斯滤波器只考虑像素之间的空间关系，而不会考虑像素值之间的关系（像素的相似度）。所以这种方法不会考虑一个像素是否位于边界。因此边界也会别模糊掉，而这正不是我们想要。双边滤波在同时使用空间高斯权重和灰度值相似性高斯权重。空间高斯函数确保只有邻近区域的像素对中心点有影响，灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。所以这种方法会确保边界不会被模糊掉，因为边界处的灰度值变化比较大。cv2.bilateralFilter

# 形态学转换

- cv2.erode ： 腐蚀
- cv2.dilate ： 膨胀
- cv2.morphologyEx ：
    - opening = cv2.morphologyEx(img, cv2.MORPH\_OPEN, kernel) ： 开运算，先腐蚀再膨胀。
    - closing = cv2.morphologyEx(img, cv2.MORPH\_CLOSE, kernel) ： 闭运算，先膨胀再腐蚀。
    - gradient = cv2.morphologyEx(img, cv2.MORPH\_GRADIENT, kernel) ， 形态学梯度，膨胀和腐蚀的区别。
    - tophat = cv2.morphologyEx(img, cv2.MORPH\_TOPHAT, kernel) ， 礼帽，原始图像与进行开运算之后得到的图像的差
    - backhat = cv2.morphologyEx(img, cv2.MORPH\_BACKHAT, kernel) ，黑帽， 进行闭运算之后得到的图像与原始图像的差。

# 图像梯度

- cv2.Sobel() ， 一阶导数
- cv2.Schar() ， 对如上的优化
- cv2.Laplacian() ， 二阶导数

边缘检测算法主要是基于图像强度的一阶和二阶导数，但导数通常对噪声很敏感，因此需要采用滤波器来过滤噪声，并调用图像增强或阈值化算法进行处理，最后再进行边缘检测

# Canny边缘检测

cv2.Canny()

 

# 图像金字塔

 

# 轮廓

- cv2.findContours ： 寻找轮廓，查找轮廓就像在黑色背景中超白色物体
    - 输入参数
        - 第一个是输入图像，
        - 第二个是轮廓检索模式，
            - cv2.RETR\_LIST : 所有轮廓在一个层级，不建立轮廓间的从属关系
            - cv2.RETR\_TREE ： 建立轮廓的从属关系
            - cv2.RETR\_EXTERNAL ： 只寻找最高层次的轮廓
            - cv2.RETR\_CCOMP ： 只有2个层级
        - 第三个是轮廓近似方法。
            -  CV\_CHAIN\_APPROX\_NONE : 保存所有的点
            - CV\_CHAIN\_APPROX\_SIMPLE ： 近保存轮廓的拐点信息
            - CV\_CHAIN\_APPROX\_TC89\_L1：使用teh-Chinl chain 近似算法;
            - CV\_CHAIN\_APPROX\_TC89\_KCOS：使用teh-Chinl chain 近似算法。
    - 输出参数
        - 第一个是图像，
        - 第二个是轮廓，
        - 第三个是（轮廓的）层析结构
- cv2.drawContours() ： 绘制轮廓

## 轮廓特征

- cv2.moments ：矩，返回的是这个轮廓的各种信息
- cv2.contourArea ： 轮廓面积
- cv2.arcLength ： 轮廓周长
- approxPolyDP(curve,epsilon,closed,approxCurve = true) ： 轮廓近似,多边形逼近，
    - curve ： 轮廓
    - epsilon ： 近似精度
        - epsilon = 0.01 \* cv2.arcLength(cnt,True) # 多边形周长与源轮廓周长之比就是epsilon
    - closed ： 是否闭合
- cv2.isContourConvex() ： 检测是否是凸包
- cv2.convexHull(points\[, clockwise\[, returnPoints\]\]\])： 获得凸包
    - points - 2D点集 2D point set
    - clockwise - 布尔类型，默认false；若为true，输出的凸包则为顺时针方向；若为false，输出的凸包则为逆时针方向。注意：这里的坐标系是x轴方向指向右侧，y轴方向指向上方
    - returnPoints - 布尔类型，默认true，在矩阵情况下，若为true，则返回凸包点集；若为false，则返回整数向量的索引
- 边界矩形
    - x,y,w,h = cv2.boundingRect(cnt)
    - rect = cv2.minAreaRect(cnt)
        - 旋转矩形交集 Cv2.RotatedRectangleIntersection
            
- (x,y),radius = cv2.minEnclosingCircle(cnt) ： 最小外接圆
- ellipse = cv2.fitEllipse(cnt) ： 椭圆拟合
- \[vx,vy,x,y\] = cv2.fitLine(cnt, cv2.DIST\_L2,0,0.01,0.01) ： 直线拟合
- 最大最小距离，一个集合到另一个集合中最近点的最大距离。
    - ```
        hausdorff_sd = cv2.createHausdorffDistanceExtractor()
        d1 = hausdorff_sd.computeDistance(cnt_hand, cnt_hand)
        ```
        
         
- 最小距离
    - 我暂时只是想到计算两个轮廓之间所有点的距离，然后选择最小值。

## 轮廓性质

- 长宽比
    
    ```
    x,y,w,h = cv2.boundingRect(cnt)
    aspect_ratio = float(w)/h
    ```
    
     

 

 

# 直方图

```
hist = cv2.calcHist([hsv], [2], None, [256],[0,255])
plt.plot(hist)
```

cv2.calcHist(images, channels, mask, histSize, ranges\[, hist\[, accumulate \]\]) ->hist

参数

- images : 输入的图像
- channels :图像的通道，
- mask : 掩码
- histSize ： 使用多少个bin(柱子)，一般为256
- ranges： 像素值的范围，一般为\[0,255\]表示0~255

 

## 直方图均衡化

createCLAHE(\[, clipLimit\[, tileGridSize\]\])

- clipLimit - 表示对比度的大小。
- tileGridSize - 表示每次处理块的大小 。

 

```
# 使用自适应直方图均衡化
# 第一步：实例化自适应直方图均衡化函数
clahe = cv2.createCLAHE(clipLimit=2.0,
                        tileGridSize=(8, 8))

# 第二步：进行自适应直方图均衡化
clahe = clahe.apply(img)

# 第三步：进行图像的展示
cv2.imshow('imgs', np.hstack((img, ret, clahe)))
cv2.waitKey(0) 
cv2.destroyAllWindows()
```

 

 

自适应彩色直方图均衡化

equalizeHist(src) -> dst

输入是8通道

 

```
import cv2
import numpy as np
import matplotlib.pyplot as plt

# 第一步：读入图片
img = cv2.imread('lena.jpeg', 0)

# 第二步: 使用 cv2.equalizeHist 实现像素点的均衡化
ret = cv2.equalizeHist(img)

# 第三步：使用 plt.hist 绘制像素直方图
plt.subplot(121)
plt.hist(img.ravel(), 256)
plt.subplot(122)
plt.hist(ret.ravel(), 256)
plt.show()

# 第四步：使用 cv2.imshow() 绘值均衡化的图像
cv2.imshow('ret', np.hstack((img, ret)))
cv2.waitKey(0)
```

 

# 抠图GrabCut

```
grabCut(img, mask, rect, bgdModel, fgdModel, iterCount, mode=None)
```

**img**：待分割的源图像，**必须是8位3通道（CV\_8UC3）图像**，在处理的过程中不会被修改； **mask**：掩码图像，如果使用掩码进行初始化，那么mask保存初始化掩码信息；在执行分割的时候，也可以将用户交互所设定的前景与背景保存到mask中，然后再传入grabCut函数；在处理结束之后，mask中会保存结果。 **mask只能取以下四种值：** GCD\_BGD（=0），背景； GCD\_FGD（=1），前景； GCD\_PR\_BGD（=2），可能的背景； GCD\_PR\_FGD（=3），可能的前景。 如果没有手工标记GCD\_BGD或者GCD\_FGD，那么结果只会有GCD\_PR\_BGD或GCD\_PR\_FGD； **rect**：用于限定需要进行分割的图像范围，只有该矩形窗口内的图像部分才被处理； **bgdModel**：背景模型，如果为null，函数内部会自动创建一个bgdModel；bgdModel必须是单通道浮点型（CV\_32FC1）图像，且行数只能为1，列数只能为13x5； **fgdModel**：前景模型，如果为null，函数内部会自动创建一个fgdModel；fgdModel必须是单通道浮点型（CV\_32FC1）图像，且行数只能为1，列数只能为13x5； **iterCount**：迭代次数，必须大于0； **mode**：用于指示grabCut函数进行什么操作，可选的值有： GC\_INIT\_WITH\_RECT（=0），用矩形窗初始化GrabCut； GC\_INIT\_WITH\_MASK（=1），用掩码图像初始化GrabCut； GC\_EVAL（=2），执行分割。

## 演示代码

```
import cv2
import numpy as np
from matplotlib import pyplot as plt

img = cv2.imread('F:/8.jpg')
OLD_IMG = img.copy()
mask = np.zeros(img.shape[:2], np.uint8)
SIZE = (1, 65)
bgdModle = np.zeros(SIZE, np.float64)
fgdModle = np.zeros(SIZE, np.float64)
rect = (1, 1, img.shape[1], img.shape[0])
cv2.grabCut(img, mask, rect, bgdModle, fgdModle, 10, cv2.GC_INIT_WITH_RECT)

mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')
img *= mask2[:, :, np.newaxis]

plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.title("grabcut"), plt.xticks([]), plt.yticks([])
plt.subplot(122), plt.imshow(cv2.cvtColor(OLD_IMG, cv2.COLOR_BGR2RGB))
plt.title("original"), plt.xticks([]), plt.yticks([])

plt.show()
```

 

# 连通区域分析

连接组件标记算法(connected component labeling algorithm)是图像分析中最常用的算法之一，算法的实质是扫描二值图像的每个像素点，对于像素值相同的而且相互连通分为相同的组(group),最终得到图像中所有的像素连通组件。

retval, labels =cv2.connectedComponents(image, connectivity, ltype)

- image, // 输入二值图像，黑色背景
- connectivity = 8, // 连通域，默认是8连通
- ltype = CV\_32, // 输出的labels类型，默认是CV\_32S 输出
- retval, //num\_labels - labels, // 输出的标记图像，背景index=0

例子，比如如下图像

[![](/assets/image/default/B12gzVL1uRA4AAAAAElFTkSuQmCC.png)](http://127.0.0.1/?attachment_id=4636)

```
# Marker labelling
ret, markers = cv2.connectedComponents(sure_fg)
# 这个是不同的连通区域显示不同的颜色
plt.imshow(markers)
```

得到的结果是下边的，可以看到一个区域就是不同的颜色。当然，需要添加  markers = markers+1 ，因为一开始的颜色是0，这里需要增加到1.

[![](/assets/image/default/wPXMHRAERNRzAAAAABJRU5ErkJggg__.png)](http://127.0.0.1/?attachment_id=4638)

 

# 距离

## 距离变换

### distanceTransform

计算二值化图像内任意一点具体最近的背景的最近的距离。

```
distanceTransform(src, distanceType, maskSize[, dst[, dstType]]) -> dst
```

- distanceType
    
    ```
    #include <imgproc.hpp>
    
    enum DistanceTypes
    {
        DIST_USER   = -1,
        DIST_L1     = 1,
        DIST_L2     = 2,
        DIST_C      = 3,
        DIST_L12    = 4,
        DIST_FAIR   = 5,
        DIST_WELSCH = 6,
        DIST_HUBER  = 7,
    };
    ```
    
     
- maskSize :
    
    ```
    enum  	cv::DistanceTransformMasks {
      cv::DIST_MASK_3 = 3,
      cv::DIST_MASK_5 = 5,
      cv::DIST_MASK_PRECISE = 0
    }
    ```
    
     

 

# 分水岭

用大于1的整数表示我们确定为前景或对象的区域，用1表示我们确定为背景或非对象的区域，最后用0表示我们无法确定的区域

```
watershed(image, markers) -> markers
```

分水岭算法的整个过程：

1. 把梯度图像中的所有像素按照灰度值进行分类，并设定一个测地距离阈值。
2. 找到灰度值最小的像素点（默认标记为灰度值最低点），让threshold从最小值开始增长，这些点为起始点。
3. 水平面在增长的过程中，会碰到周围的邻域像素，测量这些像素到起始点（灰度值最低点）的测地距离，如果小于设定阈值，则将这些像素淹没，否则在这些像素上设置大坝，这样就对这些邻域像素进行了分类。
4.  随着水平面越来越高，会设置更多更高的大坝，直到灰度值的最大值，所有区域都在分水岭线上相遇，这些大坝就对整个图像像素的进行了分区。

[![](/assets/image/default/v2-ee051f2fc107d248d52a2c6c63fc0e62_b.gif)](http://127.0.0.1/?attachment_id=4640)

# 引用

- [运用GrabCut轻松玩转抠图（python实现）](https://www.jianshu.com/p/11b5dc8f0242)
- [OpenCV 4.0 中文文档](https://opencv.apachecn.org/)
