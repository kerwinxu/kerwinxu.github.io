---
title: "几种优化解的总结"
date: "2018-02-26"
categories: 
  - "数学"
---

- # [梯度下降法](http://127.0.0.1/?p=824)
    
    - ## 要点
        
        - ### 比如线性多元方程，
            
            - $$h\_{\\theta} (x\_1,x\_2,\\cdots,x\_n)=\\theta\_0+\\theta\_1x\_1+\\theta\_nx\_n,$$
            - 损失函数函数是差的平方和 $$ J(\\theta\_0,\\theta\_1,\\cdots,\\theta\_n)=\\frac{1}{2m}\\sum\_{j=0}^{m}(h\_{\\theta}(x\_0^{(j)},x\_1^{(j)},\\cdots,x\_n^{(j)})-y\_i)^2$$
            - 所以每个变量梯度就是 $$ \\frac{\\partial J(\\theta\_0,\\theta\_1,\\theta\_n)}{\\partial \\theta\_i } = \\frac{1}{m} \\sum\_{j=0}^{m}(h\_{\\theta}(x\_0^{(j)},x\_1^{(j)},\\cdots,x\_n^{(j)})-y\_i) x\_i^j$$
            - 然后迭代求解 $$\\theta\_i = \\theta\_i – \\alpha \* \\frac{1}{m} \\sum\_{j=0}^{m}(h\_{\\theta}(x\_0^{(j)},x\_1^{(j)},\\cdots,x\_n^{(j)})-y\_i) x\_i^j$$
            - 这个导数等于0的时候，就表示最低点了，导数就是斜率，最低点的斜率为0，实际应用中往往设置一个很小的值就可以了。
    - ## 缺点
        
        - 在很逼近的时候，会很慢，甚至来回摆动。
- # [牛顿法](http://127.0.0.1/?p=1051)
    
    - ## 一元方程
        
        -  讲泰勒公式展开为2阶。$$f(x+\\Delta{x})=f(x)+f'(x)\\Delta{x}+\\frac{1}{2}f”(x)\\Delta{x}^2$$
        - 假设等号左边和f(x)近似相等，抵消掉，然后对 \\(\\Delta{x}\\)求导。得到 $$f'(x)+f”(x)\\Delta{x}=0$$
        - 更进一步 $$\\Delta{x}=-\\frac{f'(x\_n)}{f”(x\_n)}$$
        - 然后得到迭代因子 $$ x\_{n+1}=x\_{n}-\\frac{f'(x\_n)}{f”(x\_n)},n=0,1,\\cdots$$
    - ## 多元方程
        
        - $$x\_{k+1}=x\_k-H^{-1}(x\_k)J\_f(x\_k)$$
            - [$latex J\_f(x\_k)$雅可比矩阵](http://127.0.0.1/?p=1100)相当于一阶
            - [$latex H^{-1}$](http://127.0.0.1/?p=1105)相当于二阶。
    - ## 缺点
        
        - 计算这个二阶很耗内存。
- # 拟牛顿法
    
- # 共轭梯度法
