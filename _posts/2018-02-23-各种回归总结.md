---
layout: post
title: "各种回归总结"
date: "2018-02-23"
categories: 
  - "数学"
---

 

<table style="border: 1px solid #ccc;"><tbody><tr style="border: 1px solid #ccc; height: 28px;"><td style="border: 1px solid #ccc; height: 28px; text-align: center;" colspan="2">&nbsp;&nbsp;线性回归</td></tr><tr style="border: 1px solid #ccc; height: 28px;"><td style="border: 1px solid #ccc; height: 28px;">&nbsp;公式</td><td style="border: 1px solid #ccc; height: 28px;">&nbsp; $ \begin{align*}&nbsp; &amp;h_{\theta} (x_1,x_2,\cdots,x_n)=\theta_0+\theta_1x_1+\theta_2x_2+\cdots+\theta_nx_n = \theta^T x \end{align*}$</td></tr><tr style="border: 1px solid #ccc; height: 29px;"><td style="border: 1px solid #ccc; height: 29px;">&nbsp;损失函数</td><td style="border: 1px solid #ccc; height: 29px;">&nbsp;&nbsp;$ J(\theta)=\frac{1}{2m}\sum_{i=0}^{m} (h_\theta(x^i)-y^i)^2$</td></tr><tr style="border: 1px solid #ccc; height: 56px;"><td style="border: 1px solid #ccc; height: 56px;">&nbsp;损失函数梯度</td><td style="border: 1px solid #ccc; height: 56px;">&nbsp;$ \frac{\partial J(\theta_0,\theta_1,\theta_n)}{\partial \theta_i } = \frac{1}{m} \sum_{j=0}^{m}(h_{\theta}(x_0^{(j)},x_1^{(j)},\cdots,x_n^{(j)})-y_i) x_i^j ) $</td></tr></tbody></table>

 

<table style="border: 1px solid #ccc;"><tbody><tr style="border: 1px solid #ccc; height: 28px;"><td style="border: 1px solid #ccc; height: 28px; text-align: center;" colspan="2">&nbsp; 逻辑回归 logistic regression</td></tr><tr style="border: 1px solid #ccc; height: 28px;"><td style="border: 1px solid #ccc; height: 28px;">&nbsp;优势比</td><td style="border: 1px solid #ccc; height: 28px;">$ f_\theta(x)= \frac {p}{1-p}$ （p为概率）</td></tr><tr style="border: 1px solid #ccc; height: 29px;"><td style="border: 1px solid #ccc; height: 29px;">&nbsp;对数优势比</td><td style="border: 1px solid #ccc; height: 29px;">$ logit(p)=\log(\frac{p}{1-p})=\eta=f_\theta(x)=\theta^T\cdot x$</td></tr><tr style="border: 1px solid #ccc; height: 56px;"><td style="border: 1px solid #ccc; height: 56px;">&nbsp;似然函数</td><td style="border: 1px solid #ccc; height: 56px;">$ \prod^m_{i=1}\underbrace{P(y^{(i)}=1|x^{(i)})}_{where \, i\in m \, and \, y^{(i)}=1} \cdot \underbrace{P(y^{(i)}=0|x^{(i)})}_{where \, i\in m \, and \, y^{(i)}=0}=\prod^m_{i=1} P(y^{(i)}=1|x^{(i)})^{y(i)} \cdot P(y^{(i)}=0|x^{(i)})^{1-y(i)}$</td></tr><tr style="border: 1px solid #ccc; height: 56px;"><td style="border: 1px solid #ccc; height: 56px;">对数似然函数</td><td style="border: 1px solid #ccc; height: 56px;">\begin{align*} \log (\ell(\theta) )&amp;= \log (\prod^m_{i=1} P(y^{(i)}=1|x^{(i)})^{y(i)} \cdot P(y^{(i)}=0|x^{(i)})^{1-y(i)} ) \\ &amp;= \sum^m \lgroup y^{(i)} log(g(x)) + (1-y^{(i)})log(1-g(x)) \rgroup \end{align*}</td></tr></tbody></table>

 

<table style="border: 1px solid #ccc;"><tbody><tr style="border: 1px solid #ccc; height: 28px;"><td style="border: 1px solid #ccc; height: 28px; text-align: center;" colspan="2">&nbsp;softmax 回归</td></tr><tr style="border: 1px solid #ccc; height: 28px;"><td style="border: 1px solid #ccc; height: 28px;">&nbsp;公式</td><td style="border: 1px solid #ccc; height: 28px;">$ h_{\theta}(x^{(i)})= \left[ \begin{array}{c} p(y^{(i)}=1 | x^{(i)} ; \theta) \\ p(y^{(i)}=1 | x^{(2)} ; \theta) \\ \vdots \\ p(y^{(i)}=k | x^{(i)}; \theta) \end{array} \right] = \frac{1}{ \sum_{j=1}^{k} e ^{\theta_j^T x^{x(i)}}}= \left[ \begin{array}{c} e ^{\theta_1^T x^{x(i)}} \\ e ^{\theta_2^T x^{x(i)}} \\ \vdots \\ e ^{\theta_k^T x^{x(i)}} \end{array} \right]$</td></tr><tr style="border: 1px solid #ccc; height: 29px;"><td style="border: 1px solid #ccc; height: 29px;">&nbsp;损失函数</td><td style="border: 1px solid #ccc; height: 29px;">&nbsp;\[ \begin{align*} J(\theta)&amp;=-\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k 1 \{y^{(i)}=j\} \log {\frac{e^{\theta_j^T x(i)}}{\sum_{l=1}^k e^{\theta_l^T x(i)}}}\right] \\ &amp; =-\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k 1 \{y^{(i)}=j\} (\log ( e^{\theta_j^T x(i)})-\log({\sum_{l=1}^k e^{\theta_l^T x(i)}}))\right] : 对数从除法变成减法 \\ &amp; =-\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k 1 \{y^{(i)}=j\} (\theta_j^T x(i)-\log({\sum_{l=1}^k e^{\theta_l^T x(i)}}))\right] \end{align*} \]</td></tr><tr style="border: 1px solid #ccc; height: 56px;"><td style="border: 1px solid #ccc; height: 56px;">损失函数求导</td><td style="border: 1px solid #ccc; height: 56px;">\[&nbsp; &nbsp;\begin{align*} J(\theta)&amp;=-\frac{1}{m} \left[ \sum_{i=1}^m \sum_{j=1}^k \left[1\{y^{(i)}=j\} (\theta_j^T x(i)-\log({\sum_{l=1}^k e^{\theta_l^T x(i)}}))\right] \right] \\ \frac {\nabla J(\theta)} {\nabla \theta_j} &amp;= -\frac 1 m\sum_{i=1}^m \left [ {\color{blue}{\frac {\nabla\sum_{j=1}^k \left[1\{y^{(i)}=j\}\theta_j^T x^{(i)}\right]} {\nabla \theta_j}}} – \frac {\nabla \sum_{j=1}^k \left[ 1\{y^{(i)}=j\}log(\sum_{l=1}^ke^{\theta_l^T \cdot x^{(i)}})\right]} {\nabla \theta_j} \right] \\ &amp; = -\frac 1 m\sum_{i=1}^m \left [ {\color{blue}{ 1\{y^{(i)}=j\} x^{(i)}}} – \frac {\sum_{j=1}^k 1\{y^{(i)}=j\}(\sum_{l=1}^ke^{\theta_l^T \cdot x^{(i)}})’} {\sum_{l=1}^ke^{\theta_l^T \cdot x^{(i)}}} \right] \\ &amp;=-\frac 1 m\sum_{i=1}^m \left [ {\color{blue}{ 1\{y^{(i)}=j\} x^{(i)}}} – \frac {x^{(i)}e^{\theta_j^T \cdot x^{(i)}}} {\sum_{l=1}^ke^{\theta_l^T \cdot x^{(i)}}} \right] \\ &amp; = -\frac 1 m\sum_{i=1}^m x^{(i)}\left [ {\color{blue}{1\{y^{(i)}=j\}}} – p(y^{(i)}=j|x^{(i)};\theta) \right] \end{align*}\]</td></tr></tbody></table>
