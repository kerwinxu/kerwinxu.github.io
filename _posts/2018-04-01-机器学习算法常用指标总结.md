---
layout: post
title: "机器学习算法常用指标总结"
date: "2018-04-01"
categories: 
  - "数学"
---

# 前言

考虑一个二分类问题，即将实例分为正类（positive）或负类（negative），对于一个二分类问题来说，会出现四种情况。

<table><tbody><tr><td>实际</td><td>预测正</td><td>预测负</td></tr><tr><td>实际正</td><td>True positive(TP)</td><td>False Negative(FN)</td></tr><tr><td>实际负</td><td>False positive(FP)</td><td>True Negative(TN)</td></tr></tbody></table>

# TPR、FPR&TNR

## TPR

True Positive Rate = TP/(TP+FN) ：  分类器所识别的正实例占所有正实例的比率。

## FPR

False Positive Rate= FP/(FP+TN) : 分类器认识是正类的负实例占所有实例的比率

## TNR

True Negative Rate = TN/(FP+TN)=1-FPR : 分类器所识别的负实例占所有负实例的比率。

 

# 精确率Precision、召回率Recall和F1值

## Precision

精确度=提取出的正确信息条数/提取出的信息条数，衡量的是检索出来的条目，有多少是准确的。

## Recall

查全率=提取出的正确的信息条数/样本中的信息条数，衡量的是所有准确的条目，有多少被检索出来了。

## F1值

F1值=正确率\*召回率\*2/（正确率+召回率）

# 综合评价指标F-measure

这个指标是正确率和召回率的家权调和平均

\\begin{align} F=\\frac{(a^{2}+1)P\*R}{a^{2}(P+R)}\\\\P为正确率；R为召回率\\end{align}

当参数a为1时，就是如上的F1指标。F1较高说明实验方法有效。

# Roc曲线

## 为什么需要Roc曲线

Motivation1：在一个二分类模型中，对于所得到的连续结果，假设已确定一个阀值，比如说 0.6，大于这个值的实例划归为正类，小于这个值则划到负类中。如果减小阀值，减到0.5，固然能识别出更多的正类，也就是提高了识别出的正例占所有正例 的比类，即TPR,但同时也将更多的负实例当作了正实例，即提高了FPR。为了形象化这一变化，引入ROC，ROC曲线可以用于评价一个分类器。

Motivation2：在类不平衡的情况下,如正样本90个,负样本10个,直接把所有样本分类为正样本,得到识别率为90%。但这显然是没有意义的。单纯根据Precision和Recall来衡量算法的优劣已经不能表征这种病态问题。

## 什么是Roc曲线

Roc（Receiver Operating Characteristic）接收者操作曲线，曲线由两个变量1-specificity 和 Sensitivity绘制. 1-specificity=FPR，即负正类率。Sensitivity即是真正类率，TPR(True positive rate),反映了正类覆盖程度。这个组合以1-specificity对sensitivity,即是以代价(costs)对收益(benefits)。

此外，ROC曲线还可以用来计算“均值平均精度”（mean average precision），这是当你通过改变阈值来选择最好的结果时所得到的平均精度（PPV）。

为了更好地理解ROC曲线，我们使用具体的实例来说明：

如在医学诊断中,判断有病的样本。那么尽量把有病的揪出来是主要任务,也就是第一个指标TPR,要越高越好。而把没病的样本误诊为有病的,也就是第二个指标FPR,要越低越好。

不难发现,这两个指标之间是相互制约的。如果某个医生对于有病的症状比较敏感,稍微的小症状都判断为有病,那么他的第一个指标应该会很高,但是第二个指标也就相应地变高。最极端的情况下,他把所有的样本都看做有病,那么第一个指标达到1,第二个指标也为1。

我们以FPR为横轴,TPR为纵轴,得到如下ROC空间。

![](http://img1.tuicool.com/Y7beQz.png!web)

 

我们可以看出,左上角的点(TPR=1,FPR=0),为完美分类,也就是这个医生医术高明,诊断全对。点A(TPR>FPR),医生A的判断大体是正确的。中线上的点B(TPR=FPR),也就是医生B全都是蒙的,蒙对一半,蒙错一半;下半平面的点C(TPR<FPR),这个医生说你有病,那么你很可能没有病,医生C的话我们要反着听,为真庸医。上图中一个阈值,得到一个点。现在我们需要一个独立于阈值的评价指标来衡量这个医生的医术如何,也就是遍历所有的阈值,得到ROC曲线。

还是一开始的那幅图,假设如下就是某个医生的诊断统计图,直线代表阈值。我们遍历所有的阈值,能够在ROC平面上得到如下的ROC曲线。

![](/assets/image/default/764050-20160411174345379-1968591887.png)

 

曲线距离左上角越近,证明分类器效果越好。

![](/assets/image/default/764050-20160411174401488-918162160.png)

如上,是三条ROC曲线,在0.23处取一条直线。那么,在同样的低FPR=0.23的情况下,红色分类器得到更高的PTR。也就表明,ROC越往上,分类器效果越好。我们用一个标量值AUC来量化它。

# AUC

## 什么是AUC？

**AUC值为ROC曲线所覆盖的区域面积,显然,AUC越大,分类器分类效果越好。**

AUC = 1，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。

0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。

AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。

AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。

**AUC的物理意义：**假设分类器的输出是样本属于正类的socre（置信度），则AUC的物理意义为，任取一对（正、负）样本，正样本的score大于负样本的score的概率。

## 怎样计算AUC？

第一种方法:AUC为ROC曲线下的面积,那我们直接计算面积可得。面积为一个个小的梯形面积之和。计算的精度与阈值的精度有关。

第二种方法:根据AUC的物理意义,我们计算正样本score大于负样本的score的概率。取N\*M(N为正样本数,M为负样本数)个二元组,比较score,最后得到AUC。时间复杂度为O(N\*M)。

第三种方法:与第二种方法相似,直接计算正样本score大于负样本的概率。我们首先把所有样本按照score排序,依次用rank表示他们,如最大score的样本,rank=n(n=N+M),其次为n-1。那么对于正样本中rank最大的样本,rank\_max,有M-1个其他正样本比他score小,那么就有(rank\_max-1)-(M-1)个负样本比他score小。其次为(rank\_second-1)-(M-2)。最后我们得到正样本大于负样本的概率为

时间复杂度为O(N+M)。

 

 

参考$latex :$

- [http://www.cnblogs.com/maybe2030/p/5375175.html#\_label0](http://www.cnblogs.com/maybe2030/p/5375175.html#_label0)
